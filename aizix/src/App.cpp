//
// Created by Aiziboy on 2025/11/12.
//

#include <filesystem>
#include <iostream>
#include <numa.h>
#include <fmt/ranges.h>
#include <aizix/App.hpp>
#include <aizix/core/client/http_client.hpp>
#include <aizix/core/client/websocket_client.hpp>
#include <aizix/utils/logger_manager.hpp>
#include <aizix/utils/thread_utils.hpp>
#include <aizix/utils/config/ConfigLoader.hpp>
#include <nghttp2/nghttp2.h>


// çº¿ç¨‹å±€éƒ¨å­˜å‚¨ï¼šå­˜å‚¨å½“å‰çº¿ç¨‹ä¸“å±çš„ HttpClientPool æŒ‡é’ˆ
thread_local std::shared_ptr<HttpClientPool> t_local_http_client_pool = nullptr; // é»˜è®¤åˆå§‹åŒ–ä¸ºç©º

// çº¿ç¨‹å±€éƒ¨å˜é‡ï¼šå½“å‰çº¿ç¨‹åº”è¯¥ä½¿ç”¨çš„æœ¬åœ°è®¡ç®—æ± æŒ‡é’ˆ
// è¿™æ · get_local_compute_context å°±æ˜¯ O(1) çš„ï¼Œæ— é”
thread_local boost::asio::io_context* t_local_compute_ioc = nullptr;

///       æ¶æ„è®¾è®¡è¯´æ˜ (Architecture Overview)
/// ===========================================================
///
/// æœ¬æ¡†æ¶é‡‡ç”¨é«˜æ€§èƒ½çš„ "One Loop Per Thread" (OLPT) I/O æ¨¡å‹ + "Per-NUMA Node Compute Pool" è®¡ç®—æ¨¡å‹ï¼Œ
/// å¹¶ç»“åˆäº† NUMA äº²å’Œæ€§ä¼˜åŒ–ä¸ Thread-Local èµ„æºç®¡ç†ã€‚
///
/// <h3>1. I/O çº¿ç¨‹æ±  (io_context_pool_) - OLPT æ¨¡å‹</h3>
///    - åŒ…å« N ä¸ªç‹¬ç«‹çš„ `boost::asio::io_context`ï¼Œæ¯ä¸ªç»‘å®šåˆ°ä¸€ä¸ªç‹¬ç«‹çš„ç³»ç»Ÿçº¿ç¨‹å’Œ CPU æ ¸å¿ƒã€‚
///    - **io-0 (ä¸»çº¿ç¨‹)**: è´Ÿè´£ `Server` çš„è¿æ¥æ¥å— (Acceptor)ã€ä¿¡å·å¤„ç†ã€åŠå°‘é‡å…¨å±€åè°ƒä»»åŠ¡ã€‚
///    - **io-1..N (å­çº¿ç¨‹)**: è´Ÿè´£ Socket çš„è¯»å†™ã€TLS æ¡æ‰‹ã€HTTP/2 åè®®è§£æã€åŠ **æœ¬çº¿ç¨‹çš„ HttpClientPool**ã€‚
///    - **è¿æ¥åˆ†é…**: æ–°å®¢æˆ·ç«¯è¿æ¥é€šè¿‡ Round-Robin ç­–ç•¥åˆ†é…ç»™æŸä¸ª IO çº¿ç¨‹ï¼Œç»ˆèº«ç»‘å®šï¼Œæ— é”ç«äº‰ï¼ŒCache å‹å¥½ã€‚
///    - **å¤–éƒ¨è¯·æ±‚**: `HttpClient` åœ¨å“ªä¸ª IO çº¿ç¨‹è°ƒç”¨ï¼Œå°±ä½¿ç”¨å“ªä¸ª IO çº¿ç¨‹çš„ `HttpClientPool`ï¼Œå®Œå…¨å»ä¸­å¿ƒåŒ–ã€‚
///
/// <h3>2. è®¡ç®—çº¿ç¨‹æ±  (compute_context_pool_) - Per-NUMA Node Compute Pool æ¨¡å‹</h3>
///    - åŒ…å« `M` ä¸ª Worker çº¿ç¨‹ï¼Œ**æŒ‰ NUMA èŠ‚ç‚¹åˆ†ç»„**ï¼Œæ¯ä¸ªç»„å…±äº«ä¸€ä¸ª `io_context`ã€‚
///    - **NUMA ä¼˜åŒ–æ ¸å¿ƒ**: IO çº¿ç¨‹æŠ•é€’ CPU å¯†é›†å‹ä»»åŠ¡æ—¶ï¼Œåªä¼šæŠ•é€’ç»™**åŒä¸€ NUMA èŠ‚ç‚¹**çš„è®¡ç®—æ± ã€‚
///      è¿™ç¡®ä¿äº†æ•°æ®å¤„ç†å§‹ç»ˆå‘ç”Ÿåœ¨æ•°æ®æ‰€åœ¨çš„ NUMA èŠ‚ç‚¹å†…å­˜é™„è¿‘ï¼Œæ¶ˆé™¤è·¨èŠ‚ç‚¹å†…å­˜è®¿é—®çš„å»¶è¿Ÿå’Œå¸¦å®½ç“¶é¢ˆã€‚
///    - **èŒè´£**: è´Ÿè´£ CPU å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ gzip å‹ç¼©ã€å¤æ‚åŠ è§£å¯†ï¼‰ï¼Œé¿å…é˜»å¡ IO çº¿ç¨‹ã€‚
///
/// <h3>3. NUMA äº²å’Œæ€§ä¼˜åŒ–</h3>
///    - è‡ªåŠ¨æ¢æµ‹ç¡¬ä»¶æ‹“æ‰‘ï¼Œå°† IO çº¿ç¨‹å’Œè®¡ç®—çº¿ç¨‹ç²¾ç¡®ç»‘å®šåˆ°ä¸åŒçš„ CPU æ ¸å¿ƒå’Œ NUMA èŠ‚ç‚¹ã€‚
///    - <b>IO çº¿ç¨‹ï¼š</b> ä¼˜å…ˆå ç”¨æ¯ä¸ª NUMA èŠ‚ç‚¹çš„å‰å‡ ä¸ªæ ¸å¿ƒï¼Œä¿è¯ç½‘ç»œäº‹ä»¶å“åº”çš„ä½å»¶è¿Ÿã€‚
///    - <b>è®¡ç®—çº¿ç¨‹ï¼š</b> å ç”¨æ¯ä¸ª NUMA èŠ‚ç‚¹çš„å‰©ä½™æ ¸å¿ƒï¼Œé¿å…ä¸ IO çº¿ç¨‹çš„ L1/L2 ç¼“å­˜ç«äº‰ã€‚
///    - <b>èµ„æºéš”ç¦»ï¼š</b> ä¿ç•™ä¸€ä¸ªæ ¸å¿ƒç»™æ“ä½œç³»ç»Ÿä½¿ç”¨ï¼Œé¿å…æ‰€æœ‰æ ¸å¿ƒéƒ½è¢«å ç”¨ã€‚
/// =================================================================================


/**
 * @brief Application ç±»çš„æ„é€ å‡½æ•°ã€‚
 *
 * è´Ÿè´£åº”ç”¨å¯åŠ¨çš„æ—©æœŸåˆå§‹åŒ–å·¥ä½œï¼š
 * 1. æ¢æµ‹ç¡¬ä»¶ NUMA æ‹“æ‰‘ã€‚
 * 2. åˆå§‹åŒ– Per-NUMA è®¡ç®—çº¿ç¨‹æ± ã€‚
 * 3. åˆå§‹åŒ– One Loop Per Thread I/O çº¿ç¨‹æ± ã€‚
 * 4. è®¾ç½®ç”¨äºæ¥æ”¶ç»ˆæ­¢ä¿¡å·çš„ `signal_set`ã€‚
 * 5. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿã€‚
 * 6. åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡ï¼ˆServer, HttpClientPoolsï¼‰ã€‚
 */
aizix::App::App(const std::string& config_path)
    : config_(ConfigLoader::load(config_path)) {
    // 0. å…ˆæ¢æµ‹æ‹“æ‰‘ (å¿…é¡»æœ€å…ˆåšï¼Œå› ä¸ºåç»­åˆå§‹åŒ–ä¾èµ–èŠ‚ç‚¹æ•°)
    cpu_topology_ = get_numa_topology();

    // å¦‚æœæ²¡æœ‰æ¢æµ‹åˆ° NUMA èŠ‚ç‚¹ï¼Œæˆ–è€… numa_available() == -1ï¼Œ
    // åˆ™æ„é€ ä¸€ä¸ªè™šæ‹Ÿçš„â€œå•èŠ‚ç‚¹â€æ‹“æ‰‘ï¼Œä»¥ä¾¿åç»­é€»è¾‘èƒ½å…¼å®¹è¿è¡Œã€‚
    // åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰€æœ‰çš„æ ¸å¿ƒéƒ½å°†è¢«è§†ä¸ºå±äº Node 0ã€‚
    if (cpu_topology_.empty()) {
        cpu_topology_.push_back({}); // Node 0
        SPDLOG_WARN("NUMA not available or detection failed. Operating in non-NUMA compatible mode.");
        // å¦‚æœæ²¡æœ‰ NUMA ä¿¡æ¯ï¼Œæ— æ³•è¿›è¡Œç²¾ç¡®ç»‘æ ¸ï¼Œåç»­åˆ†é…å°†é€€åŒ–åˆ°ç®€å•çº¿æ€§åˆ†é…ã€‚
    }

    size_t num_nodes = std::max(static_cast<size_t>(1), cpu_topology_.size());
    SPDLOG_INFO("Initializing compute pools for {} NUMA nodes.", num_nodes);

    // 1. ä¸ºæ¯ä¸ª NUMA èŠ‚ç‚¹åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ Compute IO Context (Per-NUMA Compute Pool)
    compute_context_pool_.reserve(num_nodes);
    compute_work_guards_.reserve(num_nodes);

    for (size_t i = 0; i < num_nodes; ++i) {
        // æ¯ä¸ªèŠ‚ç‚¹çš„å¹¶å‘åº¦ hintï¼šæ€» Worker æ•° / èŠ‚ç‚¹æ•° (è‡³å°‘ä¸º 1)
        int concurrency_hint = std::max(1, static_cast<int>(config_.server.worker_threads) / static_cast<int>(num_nodes));
        auto ioc = std::make_shared<boost::asio::io_context>(concurrency_hint);
        compute_context_pool_.push_back(ioc);
        compute_work_guards_.emplace_back(make_work_guard(*ioc));
    }


    // 2. åˆå§‹åŒ– IO Context æ±  (One Loop Per Thread IO Pool)
    const size_t io_threads_count = config_.server.io_threads;
    if (io_threads_count == 0) {
        throw std::runtime_error("IO threads count must be > 0");
    }

    io_context_pool_.reserve(io_threads_count);
    io_work_guards_.reserve(io_threads_count);

    // ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ io_context
    for (size_t i = 0; i < io_threads_count; ++i) {
        // hint: 1 è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå•çº¿ç¨‹ loopï¼ŒBoost.Asio å¯ä»¥æ®æ­¤ä¼˜åŒ–å†…éƒ¨å¼€é”€ã€‚
        auto ioc = std::make_shared<boost::asio::io_context>(1);
        io_context_pool_.push_back(ioc);
        io_work_guards_.emplace_back(make_work_guard(*ioc)); // åˆ›å»º guard é˜²æ­¢ run() åœ¨æ— ä»»åŠ¡æ—¶é€€å‡º
    }

    // 3. åˆå§‹åŒ–ä¿¡å·é›† (å¿…é¡»ç»‘å®šåˆ°ä¸»çº¿ç¨‹ io-0)
    signals_ = std::make_unique<boost::asio::signal_set>(*io_context_pool_[0], SIGINT, SIGTERM);


    // åˆå§‹åŒ–æ—¥å¿—ç®¡ç†å™¨ï¼ˆå•ä¾‹ï¼‰ï¼Œåº”ç”¨å…¨å±€çš„æ—¥å¿—çº§åˆ«ã€æ ¼å¼ç­‰é…ç½®
    aizix::LoggerManager::init(config_.logging);

    // åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡ (ä¾èµ–ä¸Šè¿°æ‰€æœ‰ç»„ä»¶)
    init_services();

    // æ‰“å°ä¾èµ–åº“çš„ç‰ˆæœ¬å’Œå½“å‰å·¥ä½œç›®å½•
    const nghttp2_info* lib_info = nghttp2_version(0);
    SPDLOG_INFO("ğŸ“¦ libnghttp2 version: {}", lib_info->version_str);
    SPDLOG_INFO("ğŸ“ Workdir: {}", std::filesystem::current_path().string());

    #if defined(BOOST_ASIO_HAS_IO_URING)
    SPDLOG_INFO("Asio backend: io_uring");
    #else
    SPDLOG_INFO("Asio backend: epoll (standard)");
    #endif
}

aizix::App::~App() = default;

/**
 * @brief [Server è´Ÿè½½å‡è¡¡] è·å–ä¸‹ä¸€ä¸ª IO Contextã€‚
 *
 * ç”¨äº `Server` çš„ `Acceptor` åœ¨æ¯æ¬¡æ¥æ”¶æ–°è¿æ¥æ—¶ï¼Œé‡‡ç”¨ Round-Robin ç­–ç•¥
 * å°† Socket å‡åŒ€åˆ†é…ç»™ `io_context_pool_` ä¸­çš„ IO çº¿ç¨‹ã€‚
 * @return é€‰ä¸­çš„ `boost::asio::io_context&` å¼•ç”¨ã€‚
 */
boost::asio::io_context& aizix::App::get_ioc() {
    // ä½¿ç”¨åŸå­æ“ä½œå®ç°æ— é” Round-Robin
    const size_t index = next_io_context_.fetch_add(1, std::memory_order_relaxed);
    return *io_context_pool_[index % io_context_pool_.size()];
}

/**
 * @brief [è®¡ç®—] è·å–å½“å‰çº¿ç¨‹æ‰€å± NUMA èŠ‚ç‚¹çš„è®¡ç®— Contextã€‚
 *
 * @details
 * ä»»åŠ¡æŠ•é€’åˆ°æ­¤ Contextï¼Œå¯ç¡®ä¿ CPU å¯†é›†å‹è®¡ç®—ä»»åŠ¡åœ¨æ•°æ®æ‰€åœ¨çš„ NUMA èŠ‚ç‚¹æ‰§è¡Œï¼Œ
 * ä»è€Œå®ç°æ•°æ®å±€éƒ¨æ€§ï¼Œæ¶ˆé™¤è·¨ NUMA å†…å­˜è®¿é—®çš„å»¶è¿Ÿå’Œå¸¦å®½ç“¶é¢ˆã€‚
 * @warning å¿…é¡»åœ¨ IO çº¿ç¨‹æˆ– Worker çº¿ç¨‹ä¸­è°ƒç”¨ï¼Œå¦åˆ™å¯èƒ½è¿”å›é»˜è®¤ Node 0 çš„ Contextã€‚
 * @return å½“å‰çº¿ç¨‹æ‰€å± NUMA èŠ‚ç‚¹çš„ `boost::asio::io_context&`ã€‚
 */
boost::asio::io_context& aizix::App::get_local_compute_context() const {
    if (t_local_compute_ioc) {
        return *t_local_compute_ioc;
    }
    // Fallback: å¦‚æœåœ¨é IO/Worker çº¿ç¨‹è°ƒç”¨ (å¦‚ `main` çº¿ç¨‹å¯åŠ¨é˜¶æ®µ)ï¼Œ
    // æˆ–è€… `t_local_compute_ioc` æœªåˆå§‹åŒ– (ä¾‹å¦‚åœ¨ `compute_threads` å¯åŠ¨å‰è°ƒç”¨)ï¼Œ
    // åˆ™é»˜è®¤è¿”å›ç¬¬ 0 ä¸ª Compute Contextã€‚
    return *compute_context_pool_[0];
}

/**
 * @brief [å®¢æˆ·ç«¯] è·å–å½“å‰ IO çº¿ç¨‹ä¸“å±çš„ `HttpClientPool` å®ä¾‹ã€‚
 *
 * @warning <b>æ­¤å‡½æ•°å¿…é¡»åœ¨ IO çº¿ç¨‹ä¸­è°ƒç”¨ï¼</b> åœ¨é IO çº¿ç¨‹ï¼ˆå¦‚è®¡ç®—çº¿ç¨‹æˆ–ä¸»çº¿ç¨‹å¯åŠ¨é˜¶æ®µï¼‰
 *          è°ƒç”¨å°†æŠ›å‡º `std::runtime_error` å¼‚å¸¸ã€‚
 * @return å½“å‰ IO çº¿ç¨‹çš„ `HttpClientPool` å…±äº«æŒ‡é’ˆï¼Œå®ç°æ— é”ã€O(1) è·å–ã€‚
 */
std::shared_ptr<HttpClientPool> aizix::App::get_local_client_pool() {
    // å¦‚æœä½ åœ¨é IO çº¿ç¨‹è°ƒç”¨ï¼ˆå¦‚ main æˆ– computeï¼‰ï¼Œè¿™é‡Œå¯èƒ½æ˜¯ nullptr
    // è¿™æ˜¯ä¸€ä¸ªå¿…é¡»éµå®ˆçš„è§„çº¦ï¼šåªèƒ½åœ¨ IO çº¿ç¨‹å‘è¯·æ±‚
    if (!t_local_http_client_pool) {
        throw std::runtime_error("Attempted to access HttpClientPool from a non-IO thread or before TLS initialization");
    }
    return t_local_http_client_pool;
}

/**
 * @brief è¾…åŠ©å‡½æ•°ï¼šåˆå§‹åŒ–å½“å‰çº¿ç¨‹çš„ `HttpClientPool` thread_local æŒ‡é’ˆã€‚
 *
 * åœ¨æ¯ä¸ª IO çº¿ç¨‹å¯åŠ¨æ—¶è¢«è°ƒç”¨ï¼Œå°†å…¶å¯¹åº”çš„ `HttpClientPool` å®ä¾‹æŒ‡é’ˆå­˜å…¥ TLSã€‚
 * @param thread_index IO çº¿ç¨‹çš„ç´¢å¼• (0 ä¸ºä¸»çº¿ç¨‹)ã€‚
 */
void aizix::App::init_thread_local_pool(const size_t thread_index) const {
    if (thread_index < http_client_pools_.size()) {
        t_local_http_client_pool = http_client_pools_[thread_index];
    } else {
        // åº”è¯¥ä¸ä¼šå‘ç”Ÿï¼Œé™¤éé…ç½®çš„ IO çº¿ç¨‹æ•°å’Œå®é™…åˆ›å»ºçš„ Pool æ•°ä¸åŒ¹é…
        SPDLOG_ERROR("Attempted to initialize HttpClientPool TLS for invalid thread_index {}.", thread_index);
        t_local_http_client_pool = nullptr;
    }
}

/**
* @brief è¾…åŠ©å‡½æ•°ï¼šåˆå§‹åŒ–å½“å‰çº¿ç¨‹çš„ `compute_ioc` thread_local æŒ‡é’ˆã€‚
*
* åœ¨æ¯ä¸ª IO çº¿ç¨‹æˆ– Worker çº¿ç¨‹å¯åŠ¨æ—¶è¢«è°ƒç”¨ï¼Œå°†å…¶æ‰€å± NUMA èŠ‚ç‚¹çš„
* `compute_io_context` å®ä¾‹æŒ‡é’ˆå­˜å…¥ TLSã€‚
* @param numa_node_id çº¿ç¨‹æ‰€å±çš„ NUMA èŠ‚ç‚¹ IDã€‚
*/
void aizix::App::init_thread_local_compute_pool(const size_t numa_node_id) const {
    if (numa_node_id < compute_context_pool_.size()) {
        t_local_compute_ioc = compute_context_pool_[numa_node_id].get();
    } else {
        // Fallback: å¦‚æœ NUMA ID æ— æ•ˆï¼Œé€€åŒ–åˆ° Node 0
        SPDLOG_WARN("Invalid NUMA node ID {}. Using Node 0 compute pool.", numa_node_id);
        t_local_compute_ioc = compute_context_pool_[0].get();
    }
}


// NOLINTNEXTLINE(readability-make-member-function-const)
void aizix::App::addController(const std::vector<std::shared_ptr<aizix::HttpController>>& controllers) {
    //std::vector<std::unique_ptr<IHttpClient>> controllers;
    //controllers.emplace_back(std::make_unique<UserController>());
    //controllers.emplace_back(std::make_unique<AuthController>());
    //controllers.emplace_back(std::make_unique<FileController>());

    for (auto& controller : controllers) {
        controller->registerRoutes(server_->router());
    }
}

// NOLINTNEXTLINE(readability-make-member-function-const)
void aizix::App::addController(const std::shared_ptr<aizix::HttpController>& controller) {
    controller->registerRoutes(server_->router());
}

/**
 * @brief å°†å½“å‰çº¿ç¨‹ç»‘å®šåˆ°æŒ‡å®š CPU æ ¸å¿ƒã€‚
 * @details
 * ä½¿ç”¨ Linux çš„ `pthread_setaffinity_np` ç³»ç»Ÿè°ƒç”¨ï¼Œå°†çº¿ç¨‹å›ºå®šåœ¨æŸä¸ªæ ¸å¿ƒä¸Šè¿è¡Œã€‚
 * è¿™ç§ CPU äº²å’Œæ€§ï¼ˆCPU Affinityï¼‰å¯ä»¥å¸¦æ¥ï¼š
 * - **å‡å°‘ç¼“å­˜å¤±æ•ˆ**ï¼šçº¿ç¨‹æ€»åœ¨åŒä¸€ä¸ª CPU ä¸Šï¼Œå……åˆ†åˆ©ç”¨ L1/L2 ç¼“å­˜ã€‚
 * - **å‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€**ï¼šé¿å…æ“ä½œç³»ç»Ÿåœ¨ä¸åŒæ ¸å¿ƒé—´é¢‘ç¹è°ƒåº¦ã€‚
 * - **æ”¹å–„ NUMA æ€§èƒ½**ï¼šç¡®ä¿çº¿ç¨‹è®¿é—®çš„å†…å­˜ä¸å®ƒæ‰€åœ¨çš„ CPU åœ¨åŒä¸€ä¸ª NUMA èŠ‚ç‚¹ä¸Šã€‚
 * @param core_id è¦ç»‘å®šçš„ CPU æ ¸å¿ƒç¼–å·ï¼ˆä» 0 å¼€å§‹ï¼‰ã€‚
 */
void aizix::App::bind_thread_to_core(const size_t core_id) {
    // å®šä¹‰ä¸€ä¸ª CPU é›†åˆï¼Œç”¨æ¥æè¿°çº¿ç¨‹å¯ä»¥è¿è¡Œåœ¨å“ªäº› CPU ä¸Š
    cpu_set_t cpu_set;
    CPU_ZERO(&cpu_set);         // å°†é›†åˆæ¸…ç©ºï¼ˆæ‰€æœ‰ä½è®¾ä¸º0ï¼‰
    CPU_SET(core_id, &cpu_set); // å°†æŒ‡å®š core_id å¯¹åº”çš„ CPU åŠ å…¥é›†åˆ

    // è·å–å½“å‰çº¿ç¨‹çš„ pthread æ ‡è¯†
    const pthread_t current_thread = pthread_self();

    // è°ƒç”¨ pthread_setaffinity_np è®¾ç½®çº¿ç¨‹çš„ CPU äº²å’Œæ€§
    // ä½œç”¨ï¼šå¼ºåˆ¶å½“å‰çº¿ç¨‹åªèƒ½åœ¨æŒ‡å®šçš„ core_id ä¸Šè¿è¡Œ
    // å‚æ•°è¯´æ˜ï¼š
    //   - current_thread: å½“å‰çº¿ç¨‹
    //   - sizeof(cpu_set_t): é›†åˆå¤§å°
    //   - &cpu_set: CPU é›†åˆæŒ‡é’ˆ
    if (pthread_setaffinity_np(current_thread, sizeof(cpu_set_t), &cpu_set) != 0) {
        // å¦‚æœè¿”å›å€¼é0ï¼Œè¯´æ˜è®¾ç½®å¤±è´¥ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯
        std::cerr << "Error setting thread affinity for core " << core_id << std::endl;
        SPDLOG_ERROR("Error setting thread affinity for core {}", core_id);
    }
}

/**
 * @brief è·å–ç³»ç»Ÿçš„ NUMA (éç»Ÿä¸€å†…å­˜è®¿é—®æ¶æ„) æ‹“æ‰‘ã€‚
 * @return ä¸€ä¸ªäºŒç»´å‘é‡ï¼Œ`topology[node_id]` åŒ…å«äº†å±äºè¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ CPU æ ¸å¿ƒ IDã€‚
 *         å¦‚æœç³»ç»Ÿä¸æ”¯æŒ NUMAï¼Œåˆ™è¿”å›ç©ºå‘é‡ã€‚
 */
std::vector<std::vector<int>> aizix::App::get_numa_topology() {
    // æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æ”¯æŒ NUMA
    // å¦‚æœè¿”å› -1ï¼Œè¯´æ˜ NUMA ä¸å¯ç”¨ï¼ˆä¾‹å¦‚å•è·¯ CPU æˆ–æœªå¯ç”¨ NUMAï¼‰
    if (numa_available() == -1) {
        return {}; // è¿”å›ç©ºæ‹“æ‰‘
    }

    // è·å–ç³»ç»Ÿä¸­é…ç½®çš„ NUMA èŠ‚ç‚¹æ•°é‡
    const int nodes = numa_num_configured_nodes();

    // è·å–ç³»ç»Ÿä¸­é…ç½®çš„ CPU æ€»æ•°
    const int cpus = numa_num_configured_cpus();

    // å®šä¹‰ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼ˆvector of vectorï¼‰ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ª NUMA èŠ‚ç‚¹çš„ CPU åˆ—è¡¨
    std::vector<std::vector<int>> topology(nodes);

    // éå†æ‰€æœ‰ CPUï¼ŒæŸ¥è¯¢å®ƒå±äºå“ªä¸ª NUMA èŠ‚ç‚¹
    for (int cpu = 0; cpu < cpus; ++cpu) {
        // numa_node_of_cpu è¿”å›è¯¥ CPU æ‰€å±çš„ NUMA èŠ‚ç‚¹ç¼–å·
        int node = numa_node_of_cpu(cpu);

        // å¦‚æœèŠ‚ç‚¹ç¼–å·åˆæ³•ï¼ˆ>=0 ä¸” < èŠ‚ç‚¹æ€»æ•°ï¼‰ï¼Œåˆ™å°†è¯¥ CPU åŠ å…¥å¯¹åº”èŠ‚ç‚¹çš„åˆ—è¡¨
        if (node >= 0 && node < nodes) {
            topology[node].push_back(cpu);
        }
    }

    // è¿”å›å®Œæ•´çš„ NUMA æ‹“æ‰‘ç»“æ„
    // ä¾‹å¦‚ï¼šåœ¨åŒè·¯ CPU ç³»ç»Ÿä¸Šï¼Œå¯èƒ½è¿”å›ï¼š
    // topology[0] = {0,1,2,...,15}   // Node0 çš„ CPU
    // topology[1] = {16,17,...,31}   // Node1 çš„ CPU
    return topology;
}


/**
 * @brief [æ ¸å¿ƒ] åˆå§‹åŒ–æ‰€æœ‰çº¿ç¨‹ï¼ˆIO å’Œ Computeï¼‰å¹¶è¿›è¡Œ CPU äº²å’Œæ€§ç»‘å®šã€‚
 *
 * @details
 * æ­¤å‡½æ•°è´Ÿè´£æ ¹æ® NUMA æ‹“æ‰‘å’Œé…ç½®æ–‡ä»¶ä¸­çš„çº¿ç¨‹æ•°ï¼Œåˆç†åˆ†é…å¹¶ç»‘å®š I/O çº¿ç¨‹å’Œ Compute çº¿ç¨‹ï¼š
 *
 * <h3>åˆ†é…ç­–ç•¥ï¼š</h3>
 * - **IO çº¿ç¨‹**ï¼šä¼˜å…ˆå ç”¨æ¯ä¸ª NUMA èŠ‚ç‚¹çš„å‰å‡ ä¸ª CPU æ ¸å¿ƒï¼ˆç‹¬å ï¼‰ã€‚
 * - **Compute çº¿ç¨‹**ï¼šå ç”¨æ¯ä¸ª NUMA èŠ‚ç‚¹çš„å‰©ä½™ CPU æ ¸å¿ƒï¼ˆç‹¬å ï¼Œæˆ–åœ¨æ ¸å¿ƒä¸è¶³æ—¶å¤ç”¨ï¼‰ã€‚
 *
 * <h3>å…³é”®æ­¥éª¤ï¼š</h3>
 * 1. <b>é¢„è®¡ç®—æ ¸å¿ƒåˆ†é…ï¼š</b> åœ¨ä¸»çº¿ç¨‹ä¸­é¢„å…ˆå†³å®šæ¯ä¸ª IO å’Œ Compute çº¿ç¨‹åº”ç»‘å®šåˆ°å“ªä¸ª CPU æ ¸å¿ƒã€‚
 *    è¿™ç¡®ä¿äº† IO çº¿ç¨‹å’Œ Compute çº¿ç¨‹ä¸ä¼šäº‰æŠ¢ç›¸åŒçš„ç‰©ç†æ ¸å¿ƒã€‚
 * 2. <b>åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹ï¼š</b>
 *    - æ¯ä¸ªçº¿ç¨‹å¯åŠ¨åï¼Œé¦–å…ˆè®¾ç½®çº¿ç¨‹åç§°ã€‚
 *    - è¿›è¡Œ CPU ç»‘æ ¸ ( `bind_thread_to_core` ) å’Œ NUMA å†…å­˜ç­–ç•¥ (`numa_run_on_node`)ã€‚
 *    - <b>åˆå§‹åŒ– TLSï¼š</b> å°†å½“å‰çº¿ç¨‹æ‰€å±çš„ `HttpClientPool` å’Œ `compute_ioc` æŒ‡é’ˆå­˜å…¥çº¿ç¨‹å±€éƒ¨å­˜å‚¨ã€‚
 *    - è¿è¡Œå…¶ä¸“å±çš„ `io_context` (IO çº¿ç¨‹) æˆ– `compute_io_context` (Compute çº¿ç¨‹)ã€‚
 */
void aizix::App::setup_threading() {
    // è·å–é…ç½®ä¸­æŒ‡å®šçš„çº¿ç¨‹æ•°
    const size_t io_threads_count = config_.server.io_threads;
    const size_t worker_threads_count = config_.server.worker_threads;
    const size_t num_nodes = compute_context_pool_.size(); // NUMA èŠ‚ç‚¹æ•° (æˆ– 1)

    // 1. æ‰“å° NUMA æ‹“æ‰‘ä¿¡æ¯ (cpu_topology_ åœ¨æ„é€ å‡½æ•°å·²å¡«å……)
    SPDLOG_DEBUG("Detected {} NUMA nodes", cpu_topology_.size());
    for (size_t n = 0; n < cpu_topology_.size(); ++n) {
        SPDLOG_DEBUG("Node {} CPUs: {}", n, fmt::join(cpu_topology_[n], ", "));
    }

    // --- é¢„è®¡ç®—ï¼šçº¿ç¨‹çš„æ ¸å¿ƒåˆ†é…æ–¹æ¡ˆ ---
    // next_core_idx_in_node[node_id]ï¼šè¿½è¸ªæ¯ä¸ª NUMA èŠ‚ç‚¹ä¸‹ä¸€ä¸ªå¯åˆ†é…æ ¸å¿ƒçš„ç´¢å¼•
    std::vector<size_t> next_core_idx_in_node(num_nodes, 0);

    // å­˜å‚¨æ¯ä¸ª IO çº¿ç¨‹å’Œ Compute çº¿ç¨‹çš„æœ€ç»ˆç»‘å®šç›®æ ‡ {core_id, node_id}
    std::vector<std::pair<int, int>> io_thread_assignments(io_threads_count, {-1, -1});
    std::vector<std::pair<int, int>> compute_thread_assignments(worker_threads_count, {-1, -1});

    // --- 1. åˆ†é… IO çº¿ç¨‹çš„æ ¸å¿ƒ (io-0 åˆ° io-N-1) ---
    // ç­–ç•¥ï¼šå°½é‡å‡åŒ€åœ°ä»ä¸åŒ NUMA èŠ‚ç‚¹åˆ†é…æ ¸å¿ƒï¼Œä¼˜å…ˆä½¿ç”¨ä¸å†²çªçš„ã€‚
    if (!cpu_topology_.empty()) {
        // åªæœ‰åœ¨æ¢æµ‹åˆ°æ‹“æ‰‘æ—¶æ‰è¿›è¡Œç»‘æ ¸åˆ†é…
        for (size_t i = 0; i < io_threads_count; ++i) {
            bool assigned = false;
            // å°è¯•ä»ä¸åŒçš„ NUMA èŠ‚ç‚¹ Round-Robin åˆ†é…æ ¸å¿ƒ
            for (size_t node_iter = 0; node_iter < num_nodes; ++node_iter) {
                size_t target_node_id = (node_iter + i) % num_nodes; // è½®è¯¢ NUMA èŠ‚ç‚¹
                if (next_core_idx_in_node[target_node_id] < cpu_topology_[target_node_id].size()) {
                    int core_id = cpu_topology_[target_node_id][next_core_idx_in_node[target_node_id]];
                    io_thread_assignments[i] = {core_id, (int)target_node_id};
                    next_core_idx_in_node[target_node_id]++; // æ ‡è®°æ ¸å¿ƒå·²å ç”¨
                    assigned = true;
                    break;
                }
            }
            if (!assigned) {
                SPDLOG_WARN("Not enough physical cores for IO thread {}. It will run without dedicated core.", i);
            }
        }
    } else {
        SPDLOG_WARN("CPU topology not available. IO threads will run without core affinity.");
    }

    // --- 2. åˆ†é… Compute çº¿ç¨‹çš„æ ¸å¿ƒ (worker-0 åˆ° worker-M-1) ---
    // ç­–ç•¥ï¼šå‡åŒ€åœ°å°† Worker çº¿ç¨‹åˆ†é…åˆ° NUMA èŠ‚ç‚¹ï¼Œå¹¶ä»è¯¥èŠ‚ç‚¹çš„å‰©ä½™æ ¸å¿ƒä¸­åˆ†é…ã€‚
    if (!cpu_topology_.empty()) {
        for (size_t i = 0; i < worker_threads_count; ++i) {
            size_t target_node_id = i % num_nodes; // Round-Robin åˆ†é… Worker åˆ° NUMA èŠ‚ç‚¹
            int assigned_core = -1;

            if (next_core_idx_in_node[target_node_id] < cpu_topology_[target_node_id].size()) {
                // è¯¥ Node è¿˜æœ‰ç©ºé—²æ ¸å¿ƒï¼Œç‹¬å ä½¿ç”¨
                assigned_core = cpu_topology_[target_node_id][next_core_idx_in_node[target_node_id]];
                next_core_idx_in_node[target_node_id]++;
            } else {
                // æ ¸å¿ƒä¸è¶³ (Over-subscription)ï¼šå›ç»•å¤ç”¨è¯¥ Node ä¸Šçš„æ ¸å¿ƒã€‚
                // é¿å…è·¨ Node è®¿é—®ï¼Œä¼˜å…ˆåœ¨åŒ Node å†…å¤ç”¨ã€‚
                if (!cpu_topology_[target_node_id].empty()) {
                    assigned_core = cpu_topology_[target_node_id][i % cpu_topology_[target_node_id].size()];
                    SPDLOG_WARN("Worker thread {} over-subscribed on Node {}. Sharing core {}.", i, target_node_id, assigned_core);
                }
            }
            compute_thread_assignments[i] = {assigned_core, (int)target_node_id};
        }
    } else {
        SPDLOG_WARN("CPU topology not available. Worker threads will run without core affinity.");
    }


    // --- 2. åˆ›å»ºå¹¶å¯åŠ¨é¢å¤–çš„ IO çº¿ç¨‹  (io-1 åˆ° io-N)---
    // ä¸»çº¿ç¨‹ (io-0) ä¼šåœ¨ run() ä¸­å¤„ç†è‡ªå·±çš„åˆå§‹åŒ–å’Œè¿è¡Œ
    const size_t num_extra_io_threads = (io_threads_count > 1) ? (io_threads_count - 1) : 0;
    io_threads_.reserve(num_extra_io_threads); // é¢„åˆ†é… vector å®¹é‡ï¼Œé¿å…å¾ªç¯ä¸­å‘ç”Ÿå†…å­˜é‡åˆ†é…

    // å¾ªç¯åˆ›å»ºæ¯ä¸€ä¸ªé¢å¤–çš„ IO çº¿ç¨‹
    for (size_t i = 0; i < num_extra_io_threads; ++i) {
        // è®¡ç®—å½“å‰çº¿ç¨‹çš„å…¨å±€ç´¢å¼•ã€‚ä¸»çº¿ç¨‹ç´¢å¼•ä¸º0ï¼Œé¢å¤–çº¿ç¨‹ä»1å¼€å§‹ã€‚
        size_t thread_index = i + 1;
        auto assignment = io_thread_assignments[thread_index]; // è·å–é¢„åˆ†é…çš„æ ¸å¿ƒå’ŒèŠ‚ç‚¹

        io_threads_.emplace_back([this, thread_index, assignment]() {
            const std::string thread_name = "io-" + std::to_string(thread_index);
            ThreadUtils::set_current_thread_name(thread_name);

            // [TLS] åˆå§‹åŒ– HttpClientPool æŒ‡é’ˆ
            this->init_thread_local_pool(thread_index);

            // ç»‘å®š CPU æ ¸å¿ƒå’Œ NUMA èŠ‚ç‚¹
            if (assignment.first != -1) {
                bind_thread_to_core(assignment.first);
                if (assignment.second != -1 && numa_available() != -1) {
                    numa_run_on_node(assignment.second);
                }
                SPDLOG_INFO("IO thread '{}' bound to CPU {}, Node {}.", thread_name, assignment.first, assignment.second);
            } else {
                SPDLOG_INFO("IO thread '{}' started without core affinity.", thread_name);
            }

            // [TLS] åˆå§‹åŒ– Compute Pool æŒ‡é’ˆ
            this->init_thread_local_compute_pool(assignment.second != -1 ? assignment.second : 0); // Fallback to Node 0

            io_context_pool_[thread_index]->run();
        });
    }

    // --- 3. å¯åŠ¨ Compute (Worker) çº¿ç¨‹ (Per-NUMA Node + ç²¾ç¡®ç»‘æ ¸) ---
    compute_threads_.reserve(worker_threads_count);

    for (size_t i = 0; i < worker_threads_count; ++i) {
        auto assignment = compute_thread_assignments[i]; // è·å–é¢„åˆ†é…çš„æ ¸å¿ƒå’ŒèŠ‚ç‚¹

        compute_threads_.emplace_back([this, i, assignment]() {
            const std::string thread_name = "worker-" + std::to_string(i); // Worker ID æ˜¯å…¶åœ¨ config ä¸­çš„ç´¢å¼•
            ThreadUtils::set_current_thread_name(thread_name);

            // ç»‘å®š CPU æ ¸å¿ƒå’Œ NUMA èŠ‚ç‚¹
            if (assignment.first != -1) {
                bind_thread_to_core(assignment.first);
                if (assignment.second != -1 && numa_available() != -1) {
                    numa_run_on_node(assignment.second);
                }
                SPDLOG_INFO("Worker thread '{}' bound to CPU {}, Node {}.", thread_name, assignment.first, assignment.second);
            } else {
                // Fallback: å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ¸å¿ƒï¼Œåªç»‘å†…å­˜æˆ–ä»€ä¹ˆéƒ½ä¸åš
                if (assignment.second != -1 && numa_available() != -1) {
                    numa_run_on_node(assignment.second);
                    SPDLOG_INFO("Worker thread '{}' bound to Node {} (no dedicated core).", thread_name, assignment.second);
                } else {
                    SPDLOG_INFO("Worker thread '{}' started without core affinity.", thread_name);
                }
            }

            // [TLS] åˆå§‹åŒ– Compute Pool æŒ‡é’ˆ
            this->init_thread_local_compute_pool(assignment.second != -1 ? assignment.second : 0); // Fallback to Node 0

            compute_context_pool_[assignment.second != -1 ? assignment.second : 0]->run(); // è¿è¡Œè¯¥èŠ‚ç‚¹ä¸“å±çš„ IO Context
        });
    }
}


/**
 * @brief åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡å’Œè·¯ç”±ã€‚
 * åˆ›å»º Serverã€HttpClientPools å’Œå…¶ä»–å®¢æˆ·ç«¯ç»„ä»¶ã€‚
 */
void aizix::App::init_services() {
    // æ³¨å…¥ App è‡ªèº«å¼•ç”¨ï¼Œä»¥ä¾¿ Server å’Œ Client è·å– IO Context
    server_ = std::make_unique<Server>(*this);

    // ä¸ºæ¯ä¸ª IO Context åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ HttpClientPool (Per-Thread HttpClientPool)
    http_client_pools_.reserve(io_context_pool_.size());
    http_client_pools_.reserve(io_context_pool_.size());
    for (const auto& ioc : io_context_pool_) {
        http_client_pools_.push_back(std::make_shared<HttpClientPool>(*ioc, config_));
    }


    // HttpClient å’Œ WebSocketClient ç°åœ¨é€šè¿‡ App åŠ¨æ€è·å–å½“å‰çº¿ç¨‹çš„ Pool
    http_client_ = std::make_shared<HttpClient>(*this);
    ws_client_ = std::make_shared<WebSocketClient>(*this);
}

/**
 * @brief è®¾ç½®ä¿¡å·å¤„ç†é€»è¾‘ï¼Œå®ç°ä¼˜é›…å…³é—­ã€‚
 * ç›‘å¬ SIGINT (Ctrl+C) å’Œ SIGTERM ä¿¡å·ï¼Œè§¦å‘çº§è”å…³é—­æµç¨‹ã€‚
 */
void aizix::App::setup_signal_handling() {
    signals_->async_wait([this](const boost::system::error_code& error, int signal_number) {
        if (!error) {
            SPDLOG_INFO("Received signal {}, starting graceful shutdown...", signal_number);
            signals_->cancel(); // é˜²æ­¢é‡å¤è§¦å‘

            // åœ¨ä¸» IO çº¿ç¨‹ä¸Šå¯åŠ¨å¼‚æ­¥å…³é—­åç¨‹
            co_spawn(get_main_ioc(), [&]() -> boost::asio::awaitable<void> {
                // 1. å…³é—­ Server (åœæ­¢æ¥å—æ–°è¿æ¥ï¼Œä¼˜é›…å…³é—­ç°æœ‰ä¼šè¯)
                SPDLOG_INFO("Shutting down server sessions...");
                co_await server_->stop();

                // 2. å…³é—­æ‰€æœ‰ HttpClient Pools (å¹¶è¡Œå…³é—­æ‰€æœ‰å‡ºç«™è¿æ¥)
                SPDLOG_INFO("Shutting down client connections...");
                co_await stop_client_pools();

                // 3. åœæ­¢æ‰€æœ‰è®¡ç®—çº¿ç¨‹æ± 
                SPDLOG_INFO("Stopping compute pools...");
                compute_work_guards_.clear(); // é‡Šæ”¾ WorkGuardï¼Œå…è®¸ io_context é€€å‡º
                // å¼ºåˆ¶åœæ­¢æ‰€æœ‰è®¡ç®— io_context
                for (const auto& compute_ioc : compute_context_pool_) {
                    compute_ioc->stop();
                }


                // 4. åœæ­¢æ‰€æœ‰ IO çº¿ç¨‹æ± 
                SPDLOG_INFO("Stopping all IO contexts...");
                io_work_guards_.clear(); // é‡Šæ”¾æ‰€æœ‰ WorkGuard
                // å¼ºåˆ¶åœæ­¢æ‰€æœ‰ IO io_context
                for (const auto& ioc : io_context_pool_) {
                    ioc->stop();
                }
            }, boost::asio::detached);
        }
    });
}

/**
 * @brief å¹¶è¡Œåœæ­¢æ‰€æœ‰ `HttpClientPool` å®ä¾‹ã€‚
 * éå†æ‰€æœ‰ `HttpClientPool`ï¼Œå¹¶å°†å…¶ `stop()` æ–¹æ³•è°ƒåº¦åˆ°å…¶æ‰€å±çš„ IO çº¿ç¨‹æ‰§è¡Œã€‚
 */
boost::asio::awaitable<void> aizix::App::stop_client_pools() {
    SPDLOG_INFO("Stopping {} http client pools...", http_client_pools_.size());

    std::vector<boost::asio::awaitable<void>> tasks;
    tasks.reserve(http_client_pools_.size());

    // éå†æ‰€æœ‰ Poolï¼Œdispatch åˆ°å®ƒä»¬å„è‡ªçš„ IO çº¿ç¨‹å»æ‰§è¡Œ stop
    for (size_t i = 0; i < http_client_pools_.size(); ++i) {
        auto& pool = http_client_pools_[i];
        auto& ioc = *io_context_pool_[i];

        // å¿…é¡»åœ¨ pool æ‰€å±çš„ IO çº¿ç¨‹ä¸Šæ‰§è¡Œ stopï¼Œä»¥ä¿è¯çº¿ç¨‹å®‰å…¨ã€‚
        tasks.push_back(boost::asio::co_spawn(ioc, [pool]() -> boost::asio::awaitable<void> {
            co_await pool->stop();
        }, boost::asio::use_awaitable));
    }

    // ç­‰å¾…æ‰€æœ‰ Pool åœæ­¢ä»»åŠ¡å®Œæˆ
    for (auto& task : tasks) {
        co_await std::move(task);
    }
    SPDLOG_INFO("All http client pools stopped.");
}

/**
 * @brief åº”ç”¨ç¨‹åºä¸»è¿è¡Œå‡½æ•°ã€‚
 * è´Ÿè´£å¯åŠ¨æ•´ä¸ªåº”ç”¨çš„ç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…æ‹¬çº¿ç¨‹å¯åŠ¨ã€æœåŠ¡è¿è¡Œå’Œä¼˜é›…é€€å‡ºã€‚
 */
int aizix::App::run() {
    try {
        setup_threading(); // åˆå§‹åŒ–æ‰€æœ‰çº¿ç¨‹å’Œç»‘æ ¸

        setup_signal_handling();  // è®¾ç½®ä¼˜é›…å…³æœº

        server_->run(); // å¯åŠ¨ Server ç›‘å¬

        SPDLOG_INFO("æœåŠ¡å™¨å·²åœ¨ç«¯å£ {} ä¸Šå¯åŠ¨. IO çº¿ç¨‹æ•°: {}ï¼Œå·¥ä½œçº¿ç¨‹æ•°: {} . æŒ‰ Ctrl+C å…³é—­",
                    config_.server.port, config_.server.io_threads, config_.server.worker_threads);

        // --- ä¸»çº¿ç¨‹ (io-0) çš„åˆå§‹åŒ–å’Œè¿è¡Œ ---

        ThreadUtils::set_current_thread_name("io-0");  // ä¸»çº¿ç¨‹ name é…ç½® io-0 ä½œä¸ºç¬¬ä¸€ä¸ª IO çº¿ç¨‹

        // [TLS] åˆå§‹åŒ–ä¸»çº¿ç¨‹çš„ HttpClientPool
        this->init_thread_local_pool(0);

        // ç»‘å®šä¸»çº¿ç¨‹åˆ°æ ¸å¿ƒå¹¶åˆå§‹åŒ–å…¶è®¡ç®—æ±  TLS
        int main_node_id = 0; // é»˜è®¤ Node 0
        if (!cpu_topology_.empty() && !cpu_topology_[0].empty()) {
            const int cpu_id = cpu_topology_[0][0]; // é»˜è®¤ä½¿ç”¨ Node 0 çš„ç¬¬ä¸€ä¸ªæ ¸å¿ƒ
            const int n = numa_node_of_cpu(cpu_id);
            bind_thread_to_core(cpu_id);
            if (n != -1) {
                numa_run_on_node(n);
                main_node_id = n;
            }
            SPDLOG_INFO("Main IO thread 'io-0' bound to CPU {}, Node {}.", cpu_id, main_node_id);
        } else {
            SPDLOG_INFO("Main IO thread 'io-0' started without core affinity.");
        }

        this->init_thread_local_compute_pool(main_node_id);

        // è¿è¡Œä¸» IO Context
        io_context_pool_[0]->run();

        // æ‰€æœ‰çº¿ç¨‹ (jthread) ä¼šåœ¨ App ææ„æ—¶è‡ªåŠ¨ join
        SPDLOG_INFO("Server shut down gracefully. Exiting application.");
        return 0;
    } catch (const std::exception& e) {
        SPDLOG_ERROR("Fatal error during server execution: {}", e.what());
        spdlog::shutdown(); // ç¡®ä¿æ—¥å¿—ç³»ç»Ÿå…³é—­
        return 1;
    }catch (...) {
        SPDLOG_ERROR("Unknown fatal error during server execution.");
        spdlog::shutdown();
        return 1;
    }
}
